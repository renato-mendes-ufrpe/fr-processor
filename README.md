# RAG + LLM para ExtraÃ§Ã£o Automatizada de FormulÃ¡rios de ReferÃªncia

Sistema automatizado para extraÃ§Ã£o de informaÃ§Ãµes de FormulÃ¡rios de ReferÃªncia (FRs) usando RAG (Retrieval-Augmented Generation) com LangChain4j e Google Gemini.

## ğŸ“Š Status Atual do Projeto

### AcurÃ¡cia AlcanÃ§ada: **83.3% (20/24 questÃµes corretas)** âœ…

**EvoluÃ§Ã£o do Sistema:**
- Baseline inicial: 62.5% (15/24)
- Sistema de tipos: 79.2% (19/24)
- Chunk size otimizado: 87.5% (21/24)
- **Ground truth validado: 83.3% (20/24)** ğŸ“ *vocÃª estÃ¡ aqui*

### Resultados por Tipo de QuestÃ£o

| Tipo | Acertos | Total | Taxa | Status |
|------|---------|-------|------|--------|
| **MONETÃRIA** | 5/5 | 100% | ğŸ¯ | Perfeito |
| **TEXTO_ESPECÃFICO** | 2/2 | 100% | ğŸ¯ | Perfeito |
| **SIM/NÃƒO** | 7/9 | 77.8% | âš ï¸ | Bom |
| **CONTAGEM** | 6/8 | 75.0% | âš ï¸ | Bom |

## ğŸ¯ Funcionalidades Principais

### 1. Sistema de Tipos de QuestÃµes
- **5 tipos especializados**: MONETARIA, SIM_NAO, CONTAGEM, TEXTO_ESPECIFICO, MULTIPLA_ESCOLHA
- Prompts customizados por tipo
- PÃ³s-processamento especÃ­fico
- Enriquecimento de query contextual

### 2. RAG Otimizado
- **Embeddings locais**: AllMiniLmL6V2 (384 dimensÃµes)
- **RecuperaÃ§Ã£o contextual**: 20 chunks por query
- **Score mÃ­nimo**: 0.60
- **Chunking inteligente**: 2000 tokens com overlap de 400

### 3. Rate Limiting e Checkpoints
- Delay de 6 segundos entre requests (Gemini Free Tier - 10 RPM)
- Checkpoint automÃ¡tico a cada 5 questÃµes
- Salvamento em CSV com UTF-8 BOM (compatÃ­vel com Excel)

## ğŸ—ï¸ Arquitetura

```
src/main/java/com/example/rag/
â”œâ”€â”€ automation/
â”‚   â”œâ”€â”€ QuestionProcessor.java      # Processamento tipo-especÃ­fico
â”‚   â”œâ”€â”€ CsvQuestionReader.java      # Leitura do guia com tipos
â”‚   â”œâ”€â”€ CsvResponseWriter.java      # Escrita em CSV UTF-8 BOM
â”‚   â””â”€â”€ model/
â”‚       â”œâ”€â”€ Question.java           # Modelo com TipoQuestao
â”‚       â””â”€â”€ TipoQuestao.java        # Enum com 5 tipos
â”œâ”€â”€ config/
â”‚   â””â”€â”€ Config.java                 # ConfiguraÃ§Ãµes centralizadas
â”œâ”€â”€ extraction/
â”‚   â””â”€â”€ PdfTextExtractor.java       # Apache Tika
â”œâ”€â”€ indexing/
â”‚   â””â”€â”€ DocumentIndexer.java        # Chunking + embeddings
â”œâ”€â”€ retrieval/
â”‚   â””â”€â”€ RagQueryEngine.java         # RAG + Gemini
â””â”€â”€ RagJavaExampleApplication.java  # Main
```

## ğŸš€ Como Usar

### PrÃ©-requisitos
```bash
# Java 21+
java -version

# Gradle 9.2+
./gradlew --version
```

### ConfiguraÃ§Ã£o

1. Configure o arquivo `.env`:
```env
GEMINI_API_KEY=sua-chave-aqui
GEMINI_MODEL=gemini-2.5-flash
MAX_RESULTS_FOR_RETRIEVAL=20
MAX_SEGMENT_SIZE_IN_TOKENS=2000
SEGMENT_OVERLAP_IN_TOKENS=400
MIN_SCORE_FOR_RETRIEVAL=0.60
```

2. Prepare os arquivos de entrada:
- `data/formularios/`: PDFs dos FormulÃ¡rios de ReferÃªncia
- `Guia de Coleta.csv`: QuestÃµes a serem extraÃ­das

### Executar

```bash
# Build
./gradlew clean build

# Executar processamento completo
./gradlew run

# Ver progresso em tempo real
tail -f output/execution-log.txt

# Ver resultados
cat output/respostas.csv
```

### SaÃ­da
- `output/respostas.csv` - Respostas em formato Excel-compatÃ­vel
- `output/execution-log.txt` - Log completo da execuÃ§Ã£o
- `output/checkpoint.json` - Estado para retomar execuÃ§Ã£o

## ğŸ”§ ConfiguraÃ§Ãµes TÃ©cnicas

### Config.java (via .env)
```properties
MAX_SEGMENT_SIZE_IN_TOKENS=2000      # Tamanho do chunk (aumentado para tabelas completas)
SEGMENT_OVERLAP_IN_TOKENS=400        # Overlap entre chunks
MAX_RESULTS_FOR_RETRIEVAL=20         # Chunks recuperados por query
MIN_SCORE_FOR_RETRIEVAL=0.60         # Score mÃ­nimo de similaridade

# Rate Limiting (Gemini Free Tier)
REQUEST_DELAY_MS=6000                # 6 segundos entre requests
CHECKPOINT_FREQUENCY=5               # Salvar checkpoint a cada 5 questÃµes
```

### Tempo de ExecuÃ§Ã£o
- **24 questÃµes**: ~4-5 minutos
- **Rate limiting**: 6s entre requests (10 RPM do Gemini)
- **Checkpoints**: salvamento a cada 5 questÃµes

## ğŸ“ Formato do Guia de Coleta

Estrutura CSV:
```csv
Numero;Grau;Questao;Onde;ComoPreencher;Observacoes;Tipo
30;MÃ©dio;Quantos membros...;FR - 7.3;CONTAR a quantidade...;;CONTAGEM
```

**Tipos suportados:**
- `MONETARIA` - Valores em R$ (aplica multiplicadores mil/milhÃ£o)
- `SIM_NAO` - QuestÃµes binÃ¡rias (SIM/NÃƒO/NÃƒO DIVULGADO)
- `CONTAGEM` - Contar membros/comitÃªs (retorna nÃºmero + nomes)
- `TEXTO_ESPECIFICO` - Nomes de polÃ­ticas/auditorias
- `MULTIPLA_ESCOLHA` - Selecionar entre opÃ§Ãµes predefinidas

## ğŸ“ˆ QuestÃµes Respondidas Corretamente (20/24)

### âœ… 100% de Acerto (7 questÃµes)

**MonetÃ¡rias (5/5):**
- Q2: Receita LÃ­quida - R$ 4.872.707.000
- Q3: Lucro LÃ­quido - R$ 56.649.000
- Q6: HonorÃ¡rios Auditoria - R$ 4.380.131
- Q8: ServiÃ§os Adicionais - R$ 2.170.131

**Texto EspecÃ­fico (2/2):**
- Q5: Firma de Auditoria - BDO RCS Auditores
- Q27: PolÃ­tica de Conflitos

**SIM/NÃƒO (7/9):**
- Q10: PolÃ­tica de Riscos - SIM
- Q14: Auditoria Interna - SIM
- Q15: Controles Adequados - SIM
- Q16: DeficiÃªncias - NÃƒO
- Q18: Divulga ASG - SIM
- Q19: Conselho Fiscal - NÃƒO
- Q41: Coordenador Independente - NÃƒO

**Contagem (6/8):**
- Q23: NÃºmero de ComitÃªs - 2
- Q30: Total Conselheiros - 7
- Q31: Mulheres no Conselho - 1 (Alessandra)
- Q32: Conselheiros Externos - 2 (Alessandra, Carlos)
- Q34: Conselheiros Executivos - 1 (TÃ©rcio Jr)
- Q38: Membros ComitÃª - 2 (parcial - deveria ser 3)

### âŒ Problemas Conhecidos (4 questÃµes)

1. **Q33** - Conselheiros Independentes: RAG encontra 3, correto Ã© 4 (falta JosÃ© Carlos)
2. **Q39** - Cross-reference Conselho Ã— ComitÃª: RAG retorna 0, correto Ã© 2
3. **Q40** - Independentes no ComitÃª: RAG retorna 0, correto Ã© 2
4. **Q47** - Seguro D&O: RAG retorna "NÃ£o Divulgado", correto Ã© "NÃ£o"
5. **Q63** - Casos de Fraude: RAG retorna "SIM", correto Ã© "NÃ£o"

**PadrÃµes identificados:**
- ğŸ”´ **JosÃ© Carlos de Souza ausente** (afeta Q33, Q39, Q40)
- ğŸŸ¡ **InterpretaÃ§Ã£o de negaÃ§Ãµes** (afeta Q47, Q63)
- ğŸŸ¢ **Cross-reference entre seÃ§Ãµes** (afeta Q39, Q40)

## ğŸ” Debugging e AnÃ¡lise

### Ver chunks recuperados
```bash
grep "Preview:" output/execution-log.txt | head -20
```

### Ver scores de similaridade
```bash
grep "Score:" output/execution-log.txt | head -20
```

### Ver prompts enviados ao LLM
```bash
grep "Prompt:" output/execution-log.txt -A 10
```

### AnÃ¡lise detalhada dos resultados
```bash
# Ver arquivo de anÃ¡lise completa
cat output/ANALISE-RESULTADOS.md
```

## ğŸ¯ Roadmap

### âœ… Implementado
- [x] Sistema de tipos de questÃµes
- [x] RAG com embeddings locais
- [x] Prompts especializados por tipo
- [x] Rate limiting e checkpoints
- [x] Chunk size otimizado (2000 tokens)
- [x] Ground truth validation

### ğŸ”„ Em Progresso
- [ ] Investigar JosÃ© Carlos de Souza ausente
- [ ] Melhorar detecÃ§Ã£o de negaÃ§Ãµes no prompt
- [ ] Cross-reference entre seÃ§Ãµes do FR

### ğŸ“‹ Planejado
- [ ] Processar mÃºltiplos FRs em batch
- [ ] Interface web para upload de PDFs
- [ ] ExportaÃ§Ã£o em mÃºltiplos formatos (Excel, JSON)
- [ ] Cache de embeddings para performance
- [ ] Fine-tuning do modelo de embeddings
- [ ] Dashboard de visualizaÃ§Ã£o

## ğŸ“š Tecnologias Utilizadas

- **Java 21** - Linguagem base
- **LangChain4j 1.8.0** - Framework RAG
- **Google Gemini 2.5 Flash** - LLM (Free Tier, 10 RPM)
- **AllMiniLmL6V2** - Embeddings locais (384 dim)
- **Apache Tika** - ExtraÃ§Ã£o de texto de PDFs
- **Gradle 9.2** - Build tool
- **dotenv-java** - Gerenciamento de variÃ¡veis de ambiente

## ğŸ“– Estrutura de Arquivos

```
rag-java-example/
â”œâ”€â”€ src/main/java/com/example/rag/     # CÃ³digo fonte
â”œâ”€â”€ data/
â”‚   â””â”€â”€ formularios/                   # PDFs dos FRs
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ ground-truth.csv               # Respostas validadas
â”‚   â””â”€â”€ GROUND_TRUTH.md                # DocumentaÃ§Ã£o do ground truth
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ respostas.csv                  # Resultados (gerado)
â”‚   â”œâ”€â”€ respostas-analise_manual.csv   # ComparaÃ§Ã£o com ground truth
â”‚   â”œâ”€â”€ execution-log.txt              # Log completo (gerado)
â”‚   â”œâ”€â”€ checkpoint.json                # Estado da execuÃ§Ã£o (gerado)
â”‚   â””â”€â”€ ANALISE-RESULTADOS.md          # AnÃ¡lise detalhada
â”œâ”€â”€ Guia de Coleta.csv                 # QuestÃµes a extrair
â”œâ”€â”€ .env                               # ConfiguraÃ§Ãµes (nÃ£o versionado)
â”œâ”€â”€ .env.example                       # Template de configuraÃ§Ãµes
â””â”€â”€ README.md                          # Este arquivo

```

## ğŸ¤ Contribuindo

Para contribuir com o projeto:

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

MIT License

## ğŸ‘¥ Autores

- Desenvolvido na UFRPE
- Caso de uso: AMBIPAR ParticipaÃ§Ãµes e Empreendimentos S.A.
- ValidaÃ§Ã£o: Ground truth estabelecido em 09/11/2025

---

**Ãšltima atualizaÃ§Ã£o**: 09/11/2025  
**VersÃ£o**: 3.0 (Ground Truth Validado)  
**AcurÃ¡cia**: 83.3% (20/24 questÃµes)

Para anÃ¡lise detalhada dos resultados, veja `output/ANALISE-RESULTADOS.md`
